{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#1. Decision Tree\n",
      "####\uc758\uc0ac\uacb0\uc815\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \uc18d\uc131\uc744 \uac12\uc5d0 \ub530\ub77c \ubd84\uae30\ud558\uc5ec, \ucd5c\uc885 \uacb0\uc815\uc5d0 \uc774\ub974\ub3c4\ub85d \ud568 (\uc0ac\ub2e4\ub9ac\ud0c0\uae30\uc640 \uc720\uc0ac)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- ID3 Algorithm (\ub370\uc774\ud130\ub97c \uc5b4\ub5bb\uac8c \ubd84\ud560\ud574\uc57c \ud558\uace0, \ub370\uc774\ud130 \ubd84\ud560\uc744 \uc5b8\uc81c \uba48\ucd94\uc5b4\uc57c \ud558\ub294\uc9c0 \uc54c\ub824\uc900\ub2e4.)\n",
      "- Entropy (\ubd84\ud560\ud558\uae30\uc5d0 \uac00\uc7a5 \uc88b\uc740 \uc18d\uc131\uc744 \uce21\uc815\ud558\uace0 \ub370\uc774\ud130\ub97c \ubd84\ud560\ud558\uae30 \uc804\uc5d0 \uc815\ubcf4 \uc774\ub4dd\uc744 \uacc4\uc0b0\ud558\ub294 \ubc29\ubc95)\n",
      "- Information Gain (\ub370\uc774\ud130\ub97c \ubd84\ud560\ud558\uae30 \uc804\uacfc \ud6c4\uc758 \ubcc0\ud654)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## \ud504\ub85c\uadf8\ub798\ubc0d\n",
      "    1. \ub370\uc774\ud130\uc900\ube44\n",
      "    2. \uc5d4\ud2b8\ub85c\ud53c \uacc4\uc0b0\n",
      "    3. Information Gain \uacc4\uc0b0\n",
      "    4. decision tree \uad6c\uc870 \ub9cc\ub4e6\n",
      "    5. \ubd84\ub958"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from math import log\n",
      "import operator\n",
      "\n",
      "def createDataSet():\n",
      "    dataSet = [[1, 1, 'yes'],\n",
      "               [1, 1, 'yes'],\n",
      "               [1, 0, 'no'],\n",
      "               [0, 1, 'no'],\n",
      "               [0, 1, 'no']]\n",
      "    labels = ['no surfacing','flippers']\n",
      "    #change to discrete values\n",
      "    return dataSet, labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Entropy\n",
      "\n",
      "- \uc5d4\ud2b8\ub85c\ud53c\uc758 \uac12\uc740 0\uc5d0\uc11c 1\uc0ac\uc774\uc758 \uac12\uc744 \uac16\ub294\ub2e4.\n",
      "- \uac00\uc7a5 \ud63c\uc7a1\ub3c4\uac00 \ub192\uc740 \uc0c1\ud0dc\uc758 \uac12\uc774 1\uc774\uba70, \ud558\ub098\uc758 \ud074\ub798\uc2a4\ub85c\ub9cc \uad6c\uc131\ub41c \uc0c1\ud0dc\uc758 \uac12\uc774 0\uc774\ub2e4.\n",
      "- Decision Tree \uc54c\uace0\ub9ac\ub4ec\uc5d0\uc11c\ub294 \uc5d4\ud2b8\ub85c\ud53c\uac00 \ub192\uc740 \uc0c1\ud0dc\uc5d0\uc11c \ub0ae\uc740 \uc0c1\ud0dc\uac00 \ub418\ub3c4\ub85d \ub370\uc774\ud130\ub97c \ud2b9\uc815 \uc870\uac74\uc744 \ucc3e\uc544 \ub098\ubb34\ubaa8\uc591\uc73c\ub85c \uad6c\ubd84\ud574\ub098\uac04\ub2e4.\n",
      "\n",
      "###$ Entropy(S) = -\\sum_{i=1}^np(x_i)log_2p(x_i)$ \n",
      "\n",
      "###$P(x_i) = \\frac{freq(C_i, S)}{|S|}$\n",
      "\n",
      "- S : \uc8fc\uc5b4\uc9c4 \ub370\uc774\ud130\ub4e4\uc758 \uc9d1\ud569\n",
      "\n",
      "- $C = {C_1, C_2, C_3, ... , C_i}$ : \ud074\ub798\uc2a4 \uac12\ub4e4\uc758 \uc9d1\ud569\n",
      "\n",
      "\n",
      "- $freq(C_i, S) : S\uc5d0\uc11c class C_i \uc5d0 \uc18d\ud558\ub294 \ub808\ucf54\ub4dc\uc758 \uc218$\n",
      "\n",
      "\n",
      "- $|S|$ : \uc8fc\uc5b4\uc9c4 \ub370\uc774\ud130\ub4e4\uc758 \uc9d1\ud569\uc758 \ub370\uc774\ud130 \uac1c\uc218"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calcShannonEnt(dataSet):\n",
      "    numEntries = len(dataSet)\n",
      "    labelCounts = {}\n",
      "    for featVec in dataSet: #the the number of unique elements and their occurance\n",
      "        currentLabel = featVec[-1]\n",
      "        if currentLabel not in labelCounts.keys(): labelCounts[currentLabel] = 0\n",
      "        labelCounts[currentLabel] += 1\n",
      "    shannonEnt = 0.0\n",
      "    for key in labelCounts:\n",
      "        prob = float(labelCounts[key])/numEntries\n",
      "        shannonEnt -= prob * log(prob,2) #log base 2\n",
      "    return shannonEnt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myDat = [[1, 1, 'yes'],\n",
      "         [1, 1, 'yes'],\n",
      "         [1, 0, 'no'],\n",
      "         [0, 1, 'no'],\n",
      "         [0, 1, 'no']]\n",
      "lavels = ['no surfacing','flippers']\n",
      "\n",
      "calcShannonEnt(myDat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "0.9709505944546686"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myDat[0][-1] = 'maybe'\n",
      "print myDat\n",
      "\n",
      "calcShannonEnt(myDat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1, 1, 'maybe'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "1.3709505944546687"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Information gain"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def splitDataSet(dataSet, axis, value):\n",
      "    retDataSet = [] #\ubd84\ud560 \ub9ac\uc2a4\ud2b8 \uc0dd\uc131\n",
      "    for featVec in dataSet:\n",
      "        if featVec[axis] == value:\n",
      "            reducedFeatVec = featVec[:axis]\n",
      "            reducedFeatVec.extend(featVec[axis+1:])\n",
      "            retDataSet.append(reducedFeatVec)\n",
      "    return retDataSet"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = [1,2,3]\n",
      "b = [4,5,6]\n",
      "a.append(b)\n",
      "print a\n",
      "#a.extend(b)\n",
      "#print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1, 2, 3, [4, 5, 6]]\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myDat\n",
      "splitDataSet(myDat, 0, 1)\n",
      "#splitDataSet(myDat, 0, 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "[[1, 'maybe'], [1, 'yes'], [0, 'no']]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def chooseBestFeatureToSplit(dataSet):\n",
      "    numFeatures = len(dataSet[0]) - 1      #the last column is used for the labels\n",
      "    baseEntropy = calcShannonEnt(dataSet)\n",
      "    bestInfoGain = 0.0; bestFeature = -1\n",
      "    for i in range(numFeatures):        #iterate over all the features\n",
      "        featList = [example[i] for example in dataSet]#create a list of all the examples of this feature\n",
      "        uniqueVals = set(featList)       #get a set of unique values\n",
      "        newEntropy = 0.0\n",
      "        for value in uniqueVals:\n",
      "            subDataSet = splitDataSet(dataSet, i, value)\n",
      "            prob = len(subDataSet)/float(len(dataSet))\n",
      "            newEntropy += prob * calcShannonEnt(subDataSet)     \n",
      "        infoGain = baseEntropy - newEntropy     #calculate the info gain; ie reduction in entropy\n",
      "        if (infoGain > bestInfoGain):       #compare this to the best gain so far\n",
      "            bestInfoGain = infoGain         #if better than current best, set to best\n",
      "            bestFeature = i\n",
      "    return bestFeature           "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Decision Tree \uad6c\uc870 \ub9cc\ub4e6"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def createTree(dataSet,labels):\n",
      "    classList = [example[-1] for example in dataSet]\n",
      "    if classList.count(classList[0]) == len(classList): \n",
      "        return classList[0]#stop splitting when all of the classes are equal\n",
      "    if len(dataSet[0]) == 1: #stop splitting when there are no more features in dataSet\n",
      "        return majorityCnt(classList)\n",
      "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
      "    bestFeatLabel = labels[bestFeat]\n",
      "    myTree = {bestFeatLabel:{}}\n",
      "    del(labels[bestFeat])\n",
      "    featValues = [example[bestFeat] for example in dataSet]\n",
      "    uniqueVals = set(featValues)\n",
      "    for value in uniqueVals:\n",
      "        subLabels = labels[:]       #copy all of labels, so trees don't mess up existing labels\n",
      "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)\n",
      "    return myTree  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#2. Naive Bayes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###(1) \uc870\uac74\ubd80 \ud655\ub960\n",
      "\n",
      "$P(A|B) = {\\frac {P(A\\bigcap B)}{P(B)}}$\n",
      "\n",
      "\ud558\uc580\uacf5(W) 3\uac1c, \uac80\uc740\uacf5(B) 4\uac1c\n",
      "\uc8fc\uba38\ub2c81 B1, \uc8fc\uba38\ub2c82 B2\n",
      "\n",
      "A = \uc8fc\uba38\ub2c82(B2)\uc5d0\uc11c B = \ud558\uc580\uacf5(W)\uc774 \ub098\uc62c \ud655\ub960\n",
      "\n",
      "$P(A=B2|B=W) = {\\frac {P(B2\\bigcap W)}{P(W)}}$\n",
      "\n",
      "\n",
      "###(2) Bayesian \ud655\ub960\n",
      "\uc704\uc5d0\uc11c $P(A=B2|B=W) = {\\frac {P(B2 and W)}{P(W)}}$\n",
      "\n",
      "\uc8fc\uba38\ub2c8B2\uc5d0\uc11c \uacf5\uc744 \ud558\ub098 \ubf51\uc744 \uacbd\uc6b0 \ud770 \uacf5(W)\uc77c \ud655\ub960\uc740\n",
      "\n",
      "$P(B=W|A=B2) = {\\frac {P(B2\\ and\\ W)}{P(B2)}}$\n",
      "\n",
      "$P(W|B2) \\times P(B2) = P(W\\ and\\ B2)$\n",
      "\n",
      "\uc704 \uc2dd\uc5d0 \ub300\uc785\ud558\uba74\n",
      "$P(A=B2|B=W) = {\\frac {P(W|B2)P(B2)}{P(W)}}$\n",
      "\n",
      "\n",
      "\ud770 \uacf5\uc774 \ub098\uc654\ub294\ub370, \uc8fc\uba38\ub2c82\uc5d0\uc11c \ub098\uc654\uc744 \ud655\ub960\n",
      "\n",
      "$P(A=B2|B=W) = {\\frac {P(W|B2)P(B2)}{P(W)}} = {\\frac {(1/3)(3/7)}{(3/7)}} = 1/3$\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "ex)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import collections\n",
      "\n",
      "x=np.array(\n",
      "[('m', 'b', 't'),\n",
      " ('m', 's', 't'),\n",
      " ('g', 'q', 't'),\n",
      " ('h', 's', 't'),\n",
      " ('g', 'q', 't'),\n",
      " ('g', 'q', 'f'),\n",
      " ('g', 's', 'f'),\n",
      " ('h', 'b', 'f'),\n",
      " ('h', 'q', 'f'),\n",
      " ('m', 'b', 'f')],\n",
      " dtype=[('A','a1'),('B','a1'),('C','a1')])\n",
      "\n",
      "print x\n",
      "\n",
      "dt=np.dtype( {'names': ['A','B','C'], 'formats':['a1','a1','a1'] } )\n",
      "x=np.array(\n",
      "   [('m', 'b', 't'),\n",
      "    ('m', 's', 't'),\n",
      "    ('g', 'q', 't'),\n",
      "    ('h', 's', 't'),\n",
      "    ('g', 'q', 't'),\n",
      "    ('g', 'q', 'f'),\n",
      "    ('g', 's', 'f'),\n",
      "    ('h', 'b', 'f'),\n",
      "    ('h', 'q', 'f'),\n",
      "    ('m', 'b', 'f')],dtype=dt)\n",
      "\n",
      "print x,\n",
      "print dt\n",
      "\n",
      "#pandas data read \n",
      "data = pd.DataFrame(x)\n",
      "print data\n",
      "\n",
      "print x['A']\n",
      "print x['B']\n",
      "print x['C']\n",
      "\n",
      "#\ud655\ub960 \uad6c\ud558\ub294 \uac04\ud3b8 \ud568\uc218\n",
      "prob=lambda x: dict((i,x.count(i)/float(len(x))) for i in set(x))\n",
      "\n",
      "#prior\uc0ac\uc804\ud655\ub960\n",
      "c=x['C'].tolist()\n",
      "prior = prob(c)\n",
      "#print c\n",
      "print prior\n",
      "\n",
      "#likelihood\n",
      "#a = x[x['C']=='t']#['A']\n",
      "a = x[x['C']=='t']['A']\n",
      "a_likelihood = prob(a.tolist())\n",
      "print a\n",
      "print a_likelihood\n",
      "\n",
      "b=x[x['C']=='t']['B']\n",
      "b_likelihood=prob(b.tolist())\n",
      "print b_likelihood\n",
      "\n",
      "c=x[x['C']=='t']['B']\n",
      "c_likelihood=prob(c.tolist())\n",
      "print c_likelihood\n",
      "\n",
      "\n",
      "#xx=c.tolist()\n",
      "#print xx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('m', 'b', 't') ('m', 's', 't') ('g', 'q', 't') ('h', 's', 't')\n",
        " ('g', 'q', 't') ('g', 'q', 'f') ('g', 's', 'f') ('h', 'b', 'f')\n",
        " ('h', 'q', 'f') ('m', 'b', 'f')]\n",
        "[('m', 'b', 't') ('m', 's', 't') ('g', 'q', 't') ('h', 's', 't')\n",
        " ('g', 'q', 't') ('g', 'q', 'f') ('g', 's', 'f') ('h', 'b', 'f')\n",
        " ('h', 'q', 'f') ('m', 'b', 'f')] [('A', 'S1'), ('B', 'S1'), ('C', 'S1')]\n",
        "   A  B  C\n",
        "0  m  b  t\n",
        "1  m  s  t\n",
        "2  g  q  t\n",
        "3  h  s  t\n",
        "4  g  q  t\n",
        "5  g  q  f\n",
        "6  g  s  f\n",
        "7  h  b  f\n",
        "8  h  q  f\n",
        "9  m  b  f"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['m' 'm' 'g' 'h' 'g' 'g' 'g' 'h' 'h' 'm']\n",
        "['b' 's' 'q' 's' 'q' 'q' 's' 'b' 'q' 'b']\n",
        "['t' 't' 't' 't' 't' 'f' 'f' 'f' 'f' 'f']\n",
        "{'t': 0.5, 'f': 0.5}\n",
        "['m' 'm' 'g' 'h' 'g']\n",
        "{'h': 0.2, 'm': 0.4, 'g': 0.4}\n",
        "{'q': 0.4, 's': 0.4, 'b': 0.2}\n",
        "{'q': 0.4, 's': 0.4, 'b': 0.2}\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
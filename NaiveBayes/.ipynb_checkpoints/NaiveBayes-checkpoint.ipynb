{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###\uc870\uac74\ubd80 \ud655\ub960\n",
      "\n",
      "$P(A|B) = {\\frac {P(A\\bigcap B)}{P(B)}}$\n",
      "\n",
      "\ud558\uc580\uacf5(W)3\uac1c, \uac80\uc740\uacf5(B)4\uac1c\n",
      "\uc8fc\uba38\ub2c81 B1, \uc8fc\uba38\ub2c82 B2\n",
      "\n",
      "A=\uc8fc\uba38\ub2c82(B2)\uc5d0\uc11c B=\ud558\uc580\uacf5(W)\uc774 \ub098\uc62c \ud655\ub960\n",
      "\n",
      "$P(A=B2|B=W) = {\\frac {P(B2\\bigcap W)}{P(W)}}$\n",
      "\n",
      "\n",
      "###Bayesian \ud655\ub960\n",
      "\uc704\uc5d0\uc11c $P(A=B2|B=W) = {\\frac {P(B2 and W)}{P(W)}}$\n",
      "\n",
      "\uc8fc\uba38\ub2c8B2\uc5d0\uc11c \uacf5\uc744 \ud558\ub098 \ubf51\uc744 \uacbd\uc6b0 \ud770 \uacf5\uc77c \ud655\ub960\uc740\n",
      "\n",
      "$P(B=W|A=B2) = {\\frac {P(B2\\ and\\ W)}{P(B2)}}$\n",
      "\n",
      "$P(W|B2) \\times P(B2) = P(W\\ and\\ B2)$\n",
      "\n",
      "\uc704 \uc2dd\uc5d0 \ub300\uc785\ud558\uba74\n",
      "$P(A=B2|B=W) = {\\frac {P(W|B2)P(B2)}{P(W)}}$\n",
      "\n",
      "\n",
      "\ud770 \uacf5\uc774 \ub098\uc654\ub294\ub370, \uac00\ubc292\uc5d0\uc11c \ub098\uc654\uc744 \ud655\ub960\n",
      "\n",
      "$P(A=B2|B=W) = {\\frac {P(W|B2)P(B2)}{P(W)}} = {\\frac {(1/3)(3/7)}{(3/7)}} = 1/3$\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import collections\n",
      "\n",
      "x=np.array(\n",
      "[('m', 'b', 't'),\n",
      " ('m', 's', 't'),\n",
      " ('g', 'q', 't'),\n",
      " ('h', 's', 't'),\n",
      " ('g', 'q', 't'),\n",
      " ('g', 'q', 'f'),\n",
      " ('g', 's', 'f'),\n",
      " ('h', 'b', 'f'),\n",
      " ('h', 'q', 'f'),\n",
      " ('m', 'b', 'f')],\n",
      " dtype=[('A','a1'),('B','a1'),('C','a1')])\n",
      "\n",
      "print x\n",
      "\n",
      "dt=np.dtype( {'names': ['A','B','C'], 'formats':['a1','a1','a1'] } )\n",
      "x=np.array(\n",
      "   [('m', 'b', 't'),\n",
      "    ('m', 's', 't'),\n",
      "    ('g', 'q', 't'),\n",
      "    ('h', 's', 't'),\n",
      "    ('g', 'q', 't'),\n",
      "    ('g', 'q', 'f'),\n",
      "    ('g', 's', 'f'),\n",
      "    ('h', 'b', 'f'),\n",
      "    ('h', 'q', 'f'),\n",
      "    ('m', 'b', 'f')],dtype=dt)\n",
      "\n",
      "print x,\n",
      "print dt\n",
      "\n",
      "#pandas data read\n",
      "data = pd.DataFrame(x)\n",
      "print data\n",
      "\n",
      "print x['A']\n",
      "print x['B']\n",
      "print x['C']\n",
      "\n",
      "#\ud655\ub960 \uad6c\ud558\ub294 \uac04\ud3b8 \ud568\uc218\n",
      "prob=lambda x: dict((i,x.count(i)/float(len(x))) for i in set(x))\n",
      "\n",
      "#prior\uc0ac\uc804\ud655\ub960\n",
      "c=x['C'].tolist()\n",
      "prior = prob(c)\n",
      "#print c\n",
      "print prior\n",
      "\n",
      "#likelihood\n",
      "#a = x[x['C']=='t']#['A']\n",
      "a = x[x['C']=='t']['A']\n",
      "a_likelihood = prob(a.tolist())\n",
      "print a\n",
      "print a_likelihood\n",
      "\n",
      "b=x[x['C']=='t']['B']\n",
      "b_likelihood=prob(b.tolist())\n",
      "print b_likelihood\n",
      "\n",
      "c=x[x['C']=='t']['B']\n",
      "c_likelihood=prob(c.tolist())\n",
      "print c_likelihood\n",
      "\n",
      "\n",
      "#xx=c.tolist()\n",
      "#print xx\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('m', 'b', 't') ('m', 's', 't') ('g', 'q', 't') ('h', 's', 't')\n",
        " ('g', 'q', 't') ('g', 'q', 'f') ('g', 's', 'f') ('h', 'b', 'f')\n",
        " ('h', 'q', 'f') ('m', 'b', 'f')]\n",
        "[('m', 'b', 't') ('m', 's', 't') ('g', 'q', 't') ('h', 's', 't')\n",
        " ('g', 'q', 't') ('g', 'q', 'f') ('g', 's', 'f') ('h', 'b', 'f')\n",
        " ('h', 'q', 'f') ('m', 'b', 'f')] [('A', 'S1'), ('B', 'S1'), ('C', 'S1')]\n",
        "   A  B  C\n",
        "0  m  b  t\n",
        "1  m  s  t\n",
        "2  g  q  t\n",
        "3  h  s  t\n",
        "4  g  q  t\n",
        "5  g  q  f\n",
        "6  g  s  f\n",
        "7  h  b  f\n",
        "8  h  q  f\n",
        "9  m  b  f\n",
        "['m' 'm' 'g' 'h' 'g' 'g' 'g' 'h' 'h' 'm']\n",
        "['b' 's' 'q' 's' 'q' 'q' 's' 'b' 'q' 'b']\n",
        "['t' 't' 't' 't' 't' 'f' 'f' 'f' 'f' 'f']\n",
        "{'t': 0.5, 'f': 0.5}\n",
        "['m' 'm' 'g' 'h' 'g']\n",
        "{'h': 0.2, 'm': 0.4, 'g': 0.4}\n",
        "{'q': 0.4, 's': 0.4, 'b': 0.2}\n",
        "{'q': 0.4, 's': 0.4, 'b': 0.2}\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###\uc2a4\ud338 \uc774\uba54\uc77c \ubd84\ub958\ud558\uae30"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "mySent = 'This book is the best on Python or M.L. I have ever laid eyes upon.'\n",
      "mySent.split()\n",
      "\n",
      "regEx = re.compile('\\\\W*')\n",
      "listOfTokens = regEx.split(mySent)\n",
      "print listOfTokens\n",
      "\n",
      "[tok for tok in listOfTokens if len(tok) > 0]\n",
      "#[tok for tok in listOfTokens if len(tok) > 4]\n",
      "print tok\n",
      "\n",
      "\n",
      "emailText = open('/home/rooda/machinelearninginaction/Ch04/email/ham/6.txt').read()\n",
      "listOfTokens = regEx.split(emailText)\n",
      "print listOfTokens\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['This', 'book', 'is', 'the', 'best', 'on', 'Python', 'or', 'M', 'L', 'I', 'have', 'ever', 'laid', 'eyes', 'upon', '']\n",
        "\n",
        "['Hello', 'Since', 'you', 'are', 'an', 'owner', 'of', 'at', 'least', 'one', 'Google', 'Groups', 'group', 'that', 'uses', 'the', 'customized', 'welcome', 'message', 'pages', 'or', 'files', 'we', 'are', 'writing', 'to', 'inform', 'you', 'that', 'we', 'will', 'no', 'longer', 'be', 'supporting', 'these', 'features', 'starting', 'February', '2011', 'We', 'made', 'this', 'decision', 'so', 'that', 'we', 'can', 'focus', 'on', 'improving', 'the', 'core', 'functionalities', 'of', 'Google', 'Groups', 'mailing', 'lists', 'and', 'forum', 'discussions', 'Instead', 'of', 'these', 'features', 'we', 'encourage', 'you', 'to', 'use', 'products', 'that', 'are', 'designed', 'specifically', 'for', 'file', 'storage', 'and', 'page', 'creation', 'such', 'as', 'Google', 'Docs', 'and', 'Google', 'Sites', 'For', 'example', 'you', 'can', 'easily', 'create', 'your', 'pages', 'on', 'Google', 'Sites', 'and', 'share', 'the', 'site', 'http', 'www', 'google', 'com', 'support', 'sites', 'bin', 'answer', 'py', 'hl', 'en', 'answer', '174623', 'with', 'the', 'members', 'of', 'your', 'group', 'You', 'can', 'also', 'store', 'your', 'files', 'on', 'the', 'site', 'by', 'attaching', 'files', 'to', 'pages', 'http', 'www', 'google', 'com', 'support', 'sites', 'bin', 'answer', 'py', 'hl', 'en', 'answer', '90563', 'on', 'the', 'site', 'If', 'you', 're', 'just', 'looking', 'for', 'a', 'place', 'to', 'upload', 'your', 'files', 'so', 'that', 'your', 'group', 'members', 'can', 'download', 'them', 'we', 'suggest', 'you', 'try', 'Google', 'Docs', 'You', 'can', 'upload', 'files', 'http', 'docs', 'google', 'com', 'support', 'bin', 'answer', 'py', 'hl', 'en', 'answer', '50092', 'and', 'share', 'access', 'with', 'either', 'a', 'group', 'http', 'docs', 'google', 'com', 'support', 'bin', 'answer', 'py', 'hl', 'en', 'answer', '66343', 'or', 'an', 'individual', 'http', 'docs', 'google', 'com', 'support', 'bin', 'answer', 'py', 'hl', 'en', 'answer', '86152', 'assigning', 'either', 'edit', 'or', 'download', 'only', 'access', 'to', 'the', 'files', 'you', 'have', 'received', 'this', 'mandatory', 'email', 'service', 'announcement', 'to', 'update', 'you', 'about', 'important', 'changes', 'to', 'Google', 'Groups', '']\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}